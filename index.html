<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>JARVIS AI Voice Assistant</title>
  <style>
    body {
      background: radial-gradient(#000010, #000000);
      color: #00ffee;
      font-family: 'Orbitron', sans-serif;
      margin: 0;
      padding: 0;
      overflow: hidden;
    }

    .center {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      text-align: center;
    }

    h1 {
      font-size: 40px;
      color: #00ffff;
      text-shadow: 0 0 10px #00ffee;
    }

    .wave {
      width: 50px;
      height: 50px;
      border: 5px solid #00ffee;
      border-radius: 50%;
      animation: pulse 1s infinite;
      margin: 20px auto;
    }

    @keyframes pulse {
      0% {
        transform: scale(1);
        opacity: 0.7;
      }
      100% {
        transform: scale(1.5);
        opacity: 0;
      }
    }

    .log {
      color: #fff;
      padding: 10px;
      max-width: 500px;
      margin: auto;
      font-size: 14px;
      height: 200px;
      overflow-y: auto;
      background: rgba(255, 255, 255, 0.05);
      border-radius: 10px;
    }

  </style>
</head>
<body>
  <div class="center">
    <h1>JARVIS AI</h1>
    <div class="wave"></div>
    <div class="log" id="log"></div>
  </div>

  <script>
    const synth = window.speechSynthesis;
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = true;
    recognition.lang = 'en-US';
    recognition.interimResults = false;

    const log = (msg) => {
      const logBox = document.getElementById('log');
      logBox.innerHTML += `<div>> ${msg}</div>`;
      logBox.scrollTop = logBox.scrollHeight;
    };

    const speak = (text) => {
      const utter = new SpeechSynthesisUtterance(text);
      utter.rate = 1.1;
      utter.pitch = 1.2;
      synth.speak(utter);
      log("JARVIS: " + text);
    };

    const getWeather = async () => {
      try {
        const locRes = await fetch('https://ipapi.co/json');
        const locData = await locRes.json();
        const city = locData.city;
        const weatherRes = await fetch(`https://wttr.in/${city}?format=%C+%t`);
        const weather = await weatherRes.text();
        speak(`Current weather in ${city} is ${weather}`);
      } catch (e) {
        speak("Unable to fetch weather.");
      }
    };

    const checkReminders = () => {
      const reminder = localStorage.getItem("jarvis_reminder");
      const date = localStorage.getItem("jarvis_reminder_date");
      const today = new Date().toDateString();
      if (reminder && date && date !== today) {
        speak(`Reminder from yesterday: ${reminder}`);
        localStorage.removeItem("jarvis_reminder");
        localStorage.removeItem("jarvis_reminder_date");
      }
    };

    const setReminder = (msg) => {
      localStorage.setItem("jarvis_reminder", msg);
      localStorage.setItem("jarvis_reminder_date", new Date().toDateString());
      speak("Reminder has been set for tomorrow.");
    };

    const playMusic = () => {
      const audio = new Audio('https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3');
      audio.play();
      speak("Playing music now.");
    };

    const askOpenAI = async (question) => {
      speak("Thinking...");
      const res = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": "Bearer YOUR_OPENAI_API_KEY"
        },
        body: JSON.stringify({
          model: "gpt-3.5-turbo",
          messages: [{ role: "user", content: question }]
        })
      });
      const data = await res.json();
      const answer = data.choices[0].message.content;
      speak(answer);
    };

    recognition.onresult = async (event) => {
      const transcript = event.results[event.resultIndex][0].transcript.trim().toLowerCase();
      log("You: " + transcript);

      if (transcript.includes("weather")) {
        getWeather();
      } else if (transcript.includes("remind me to")) {
        const reminder = transcript.split("remind me to")[1].trim();
        setReminder(reminder);
      } else if (transcript.includes("play music")) {
        playMusic();
      } else if (transcript.includes("hello jarvis") || transcript.includes("hi jarvis")) {
        speak("Hello, how can I help you?");
      } else {
        askOpenAI(transcript);
      }
    };

    recognition.onerror = (e) => {
      log("Error: " + e.error);
      recognition.stop();
      setTimeout(() => recognition.start(), 2000);
    };

    recognition.onend = () => {
      recognition.start(); // Restart on end
    };

    window.onload = () => {
      checkReminders();
      recognition.start();
      speak("System online. Awaiting your command.");
    };
  </script>
</body>
</html>
